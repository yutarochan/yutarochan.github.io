<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Amaranth's </title>
    <description>Just another minimalist Jekyll theme for technical writing.</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 30 Mar 2019 01:35:02 -0400</pubDate>
    <lastBuildDate>Sat, 30 Mar 2019 01:35:02 -0400</lastBuildDate>
    <generator>Jekyll v3.8.4</generator>
    
      <item>
        <title>Book Feature: 機械学習エンジニアになりたい人のための本 AIを天職にする</title>
        <description>&lt;p&gt;It’s been a while since I have last posted any substantial material on my blog,
but I would like to make an exciting announcement. I am pleased to announce that
I have helped to contribute content for a new publication titled,
“機械学習エンジニアになりたい人のための本 AIを天職にする” or in English,
“The Book For People Who Want To Become A Machine Learning Engineer or Want to Get Into the AI Industry”.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;https://images-fe.ssl-images-amazon.com/images/I/51YgQBVIfpL.jpg&quot; height=&quot;300px&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;This book is aimed towards beginners and professionals who are already working in other
sectors of the industry to arm them with the knowledge they need to enter into the
profession of a Machine Learning Engineer as well as applying the latest methods and
integrate the state-of-the-art methods into their domain.&lt;/p&gt;

&lt;p&gt;The book covers contents from various resources, studying and learning resources,
to interviews of professionals within the field to obtain a birds-eye view of the overall profession.
The book is divided into two key sections: one for “Aspiring ML Engineers” which are
looking to getting into the industry and understanding what they need to know to get
a job as a Machine Learning Engineer, and the other for “Domain-Applied ML Practitioners” or
those that want to implement or apply Machine Learning into their existing workflow or
domain space through introducing the know-how and ways to develop prototypes and
deploy them.&lt;/p&gt;

&lt;p&gt;Although this book is only available in Japanese, it plays a pretty strategic role
in how it provides various resources and starting points for those that are not
sure where to get started. This book is not only both appropriate for novices but
also advanced and well-seasoned practitioners as they also provide very great insights
in the ways to keep up with the latest research and obtain code and materials for
existing implementations.&lt;/p&gt;

&lt;p&gt;The book authored by Daisuke Ishii, the founder of &lt;a href=&quot;http://www.jenio.co/&quot;&gt;Jenio Inc.&lt;/a&gt; and
organizer of the Tokyo meetup group &lt;a href=&quot;https://www.team-ai.com/&quot;&gt;TeamAI&lt;/a&gt;. It has been my
pleasure to collaborate with him on one of the chapters, dedicated to applying
machine learning within an existing domain or company and describing the fundamentals
behind what it takes to fully deploy a production grade system.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/2019-03-29_img2.jpg&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;I met Daisuke through one of the largest and most dominant Facebook groups,
Artificial Intelligence and Deep Learning group. It was then he approached me to help
contribute some contents, and spurred an exchange of information between us in
sharing knowledge of the developments and state-of-the-art from the US to the Japanese
Data Science community. Last winter, during my visit to Tokyo for my winter break, I
have also given a talk on Affective Computing work as a special guest speaker.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/2019-03-29_img1.jpg&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;If you are interested in the Japanese market of Machine Learning and are looking
into getting into the Japanese market as a Data Scientist, this book is a must-read!&lt;/p&gt;

&lt;p&gt;You can purchase a soft-covered copy or a Kindle version through Amazon.co.jp  &lt;a href=&quot;https://www.amazon.co.jp/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%AB%E3%81%AA%E3%82%8A%E3%81%9F%E3%81%84%E4%BA%BA%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E6%9C%AC-AI%E3%82%92%E5%A4%A9%E8%81%B7%E3%81%AB%E3%81%99%E3%82%8B-%E7%9F%B3%E4%BA%95-%E5%A4%A7%E8%BC%94-ebook/dp/B07GWM4J7H&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Thu, 28 Mar 2019 20:00:00 -0400</pubDate>
        <link>http://localhost:4000/2019/ml-practitioner-book/</link>
        <guid isPermaLink="true">http://localhost:4000/2019/ml-practitioner-book/</guid>
        
        
      </item>
    
      <item>
        <title>Getting RE:Settled</title>
        <description>&lt;p&gt;Recently, I have reworked my template again to manage the structure and organization of my site. I decided to go with a simpler theme (shout out to &lt;img src=&quot;https://heiswayi.nrird.com/&quot; alt=&quot;heiswayi&quot; /&gt; for the awesome theme!).&lt;/p&gt;

&lt;p&gt;For long, I have worked on various projects, learned a lot and decided it was time to start documenting these ideas down and sharing what I have learned though these experiences.
In particular I would like to use this space as a means to showcase my work, break down and implement state-of-the-art research papers, and make it an effort to improve my overall communication skills in how I can
provide technical knowledge and content in a precise, simple and concise manner.&lt;/p&gt;

&lt;p&gt;I hope that you will enjoy the new journey and posts as I hope to periodically update this blog with new and interesting content that many will enjoy.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Until then see you in the next post!  ヾ(´∀｀)ﾉ&lt;/p&gt;
</description>
        <pubDate>Tue, 24 Jul 2018 17:00:00 -0400</pubDate>
        <link>http://localhost:4000/2018/getting-resettled/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/getting-resettled/</guid>
        
        
      </item>
    
      <item>
        <title>A Web-Based FaceRig + Live2D Implementation</title>
        <description>&lt;p&gt;The following blog post was based on an original post I wrote for
&lt;a href=&quot;http://qiita.com/yutarochan/items/6f08bfa7b20709a6b3ba&quot;&gt;Qiita&lt;/a&gt; and was translated
from Japanese. Also, due to TOS reasons with the Live2D SDK, I cannot post the source
code to this implementation.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;With the recent hype surrounding &lt;a href=&quot;https://facerig.com/&quot;&gt;FaceRig&lt;/a&gt; and the release
of their &lt;a href=&quot;http://www.live2d.com/en/&quot;&gt;Live2D&lt;/a&gt; module, it was certainly interesting
to see two really interesting pieces of technology merge into one neat application
for use in areas like gaming and new human-computer interaction systems.&lt;/p&gt;

&lt;iframe width=&quot;480&quot; height=&quot;270&quot; src=&quot;https://www.youtube.com/embed/IINyowbMqJI&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;With that, I wanted to take this an opportunity to hack together a quick-and-dirty
web-based implementation of FaceRig’s Live2D module for a web browser. Of course
further refinements to improve the tracking ability or the fluidity of the animation
in the future.&lt;/p&gt;

&lt;p&gt;In the past, I have implemented a demo of Live2D on a browser based on OpenGL.
For this implementation, I have utilized the same Live2D demo codebase and will
simply look through the SDK to be able to adjust the parameters to deform the angular
direction of the character’s face.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://qiita-image-store.s3.amazonaws.com/0/64623/4d5fed48-372d-c3b9-0a3f-ddbd5c633e93.png&quot; alt=&quot;Implementation of the Web Version of Live2D&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For facial tracking, I implemented a &lt;a href=&quot;https://github.com/auduno/clmtrackr&quot;&gt;Javascript based facial tracker&lt;/a&gt; based on the
&lt;a href=&quot;http://dl.acm.org/citation.cfm?id=1938021&quot;&gt;Constrained Local Models&lt;/a&gt; from
Saragih et. al’s paper. This works fairly well for a prototype (although not really perfect), however can
probably truly optimized with either a better model or a completely new tracking
algorithm (such as implementing a Lucas-Kanade Optical Flow based tracker in Javascript).
But for now, this would suffice to at least get some of the primary functions of facial feature tracking down.&lt;/p&gt;

&lt;p&gt;Below you can see the facial feature tracking algorithm in action:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://qiita-image-store.s3.amazonaws.com/0/64623/c37157ae-f985-0b30-3cdc-87a4f05e49ed.png&quot; alt=&quot;Facial Feature Tracking Demo 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://qiita-image-store.s3.amazonaws.com/0/64623/f93cbf6a-e568-da2d-93cc-526ac90290c0.png&quot; alt=&quot;Hey look mom, I'm Iron Man!&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The original source for the OpenGL based Live2D implemented a mouse based tracker
which would use the mouse pointer’s coordinates as a means to rotate and morph the
face to the corresponding angle of where the pointer is. The plan here is to map the
facial feature tracking coordinates to the mouse pointer and attempt to move the
character’s face.&lt;/p&gt;

&lt;p&gt;For a very naive approach, we can use the nose as a key point to have it track only
the rotation of the head for our initial implementation. Further down the road we
can utilize these parameters to further optimize the tracking of the facial features.&lt;/p&gt;

&lt;p&gt;We will use the coordinate point number 62 as our tracking point for the facial tracking.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://qiita-image-store.s3.amazonaws.com/0/64623/de76edbf-2b1c-fed4-8581-b7bf53667fe3.png&quot; alt=&quot;Facial Coordinates&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Using the above method, I was able to make the head rotate slightly - but not fluidly
enough like the original implementation as the magnitude of movement is very small.
To fix this, we may have to normalize the values so that the movement of our face would
be greater for the corresponding head movements captured from the camera.&lt;/p&gt;

&lt;p&gt;For now, this was a quick-and-dirty implementation of FaceRig Live2D module. However,
down the road we can maybe use a better tracking algorithm to track certain features of
the face with greater accuracy (using deep learning models maybe). Furthermore, we can
dig into the Live2D SDK to see how we can morph some of the facial features to get a better
control over the visual aspects of the avatar.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://qiita-image-store.s3.amazonaws.com/0/64623/db700e2f-cacf-471a-bd4a-f7231af98e9a.png&quot; alt=&quot;The Final Product&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 07 Mar 2016 19:00:01 -0500</pubDate>
        <link>http://localhost:4000/2016/facerig-live2d/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/facerig-live2d/</guid>
        
        
      </item>
    
      <item>
        <title>Getting Settled</title>
        <description>&lt;p&gt;Welcome to my first post where I hope to keep this as a small personal corner of the web to write out my thoughts, ideas, tutorials, and latest developments. I hope to post on topics such as:&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Artificial Intelligence, Machine Learning, Neural Networks and Deep Learning&lt;/li&gt;
  &lt;li&gt;Tricks, Hacks, and Useful Techniques I Use on a Day-to-Day Basis&lt;/li&gt;
  &lt;li&gt;Recent News, Accomplishments, Retrospective Posts and Experiences&lt;/li&gt;
  &lt;li&gt;Research and other Professional Developments&lt;/li&gt;
  &lt;li&gt;Random Thoughts Experiments and Ideas&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;If you would like to keep in touch with me, you can do so through my email at &lt;a href=&quot;mailto:yuyajeremyong@gmail.com&quot;&gt;yuyajeremyong@gmail.com&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Also, you can subscribe to my atom feel through &lt;a href=&quot;http://yutarochan.github.io/feed.xml&quot;&gt;here&lt;/a&gt; to get the latest feed in your RSS reader.&lt;/p&gt;
</description>
        <pubDate>Sun, 06 Mar 2016 16:44:00 -0500</pubDate>
        <link>http://localhost:4000/2016/getting-settled/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/getting-settled/</guid>
        
        
      </item>
    
  </channel>
</rss>
